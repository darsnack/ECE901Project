The first experiment will be to study training performance of the ImageNet dataset on Amazon EC2, which will serve as a baseline for a traditional single-machine CPU setting.  We propose to use TensorFlow, an open-source, python-based machine learning package released by Google in November 2015 \cite{tensorflow}.  In addition, using packages in TensorFlow, we will study GPU acceleration on Amazon EC2.  Due to TensorFlowâ€™s distributed execution capability, we also propose to train CNNs using the {\sc{Hogwild!}} algorithm.  Since SGD is inherently serial, our FPGA implementation targets lowering cost per iteration.  This can be compared to {\sc{Hogwild!}}, which is a parallelized approach to achieving speedup.  Due to the variety of structural and parameter design choices typical in building a CNN, we also propose to examine several CNN architectures in combination with the different hardware platforms considered in this project.  Different activation functions including sign, ReLU, and sigmoid also will be explored.
